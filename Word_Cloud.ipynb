{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/af/849edf14d573eba9c8082db898ff0d090428d9485371cc4fe21a66717ad2/wordcloud-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 625kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in ./anaconda3/lib/python3.6/site-packages (from wordcloud) (1.14.3)\n",
      "Requirement already satisfied: pillow in ./anaconda3/lib/python3.6/site-packages (from wordcloud) (5.1.0)\n",
      "\u001b[31mdistributed 1.21.8 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.5.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#pip install matplotlib\n",
    "#pip install pandas\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessery modules \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    " \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/madhav/Documents/Data_for_Exploratory/train_data.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Travel Confirmation</td>\n",
       "      <td>Record Locator : HQGWCY - Release tickets: Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Travel Confirmation</td>\n",
       "      <td>Record Locator : ZNUPUE - Release tickets: Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travel Confirmation</td>\n",
       "      <td>Release tickets: Travel approved to TAS Securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Travel Confirmation</td>\n",
       "      <td>Release tickets: Travel approved to TAS Securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Travel Confirmation</td>\n",
       "      <td>Record Locator : DXERDW - Release tickets: Tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                               text\n",
       "0  Travel Confirmation  Record Locator : HQGWCY - Release tickets: Tra...\n",
       "1  Travel Confirmation  Record Locator : ZNUPUE - Release tickets: Tra...\n",
       "2  Travel Confirmation  Release tickets: Travel approved to TAS Securi...\n",
       "3  Travel Confirmation  Release tickets: Travel approved to TAS Securi...\n",
       "4  Travel Confirmation  Record Locator : DXERDW - Release tickets: Tra..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the csv file \n",
    "for val in data.text: \n",
    "      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "          \n",
    "    #for words in tokens: \n",
    "    #comment_words = print(comment_words, words,' ')\n",
    "   \n",
    " #wordcloud = WordCloud(width = 800, height = 800, background_color ='white', stopwords = stopwords, min_font_size = 10).data.text)\n",
    "#wordcloud = WordCloud().generate(data.text)\n",
    "\n",
    "\n",
    "# Display the generated image:\n",
    "#plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#plt.axis(\"off\")\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_only = re.sub(\"[^a-zA-Z]\",\" \",str(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RE: MAL#1453 - Mohamed El Badawy - Mali <<#3095306-89882368-130441737#>>  Hello,\\n\\nOk I will get passport and photos the day after tomorrow. Do I need tp go to the embassy or it will be only your REP?\\n\\nFor Concur request, I'm following its approval.\\n\\nThanks.\\n\\nRegards,\\nM.Badawy\\n+201229165469\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['re:',\n",
       " 'mal#1453',\n",
       " '-',\n",
       " 'mohamed',\n",
       " 'el',\n",
       " 'badawy',\n",
       " '-',\n",
       " 'mali',\n",
       " '<<#3095306-89882368-130441737#>>',\n",
       " 'hello,',\n",
       " 'ok',\n",
       " 'i',\n",
       " 'will',\n",
       " 'get',\n",
       " 'passport',\n",
       " 'and',\n",
       " 'photos',\n",
       " 'the',\n",
       " 'day',\n",
       " 'after',\n",
       " 'tomorrow.',\n",
       " 'do',\n",
       " 'i',\n",
       " 'need',\n",
       " 'tp',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'embassy',\n",
       " 'or',\n",
       " 'it',\n",
       " 'will',\n",
       " 'be',\n",
       " 'only',\n",
       " 'your',\n",
       " 'rep?',\n",
       " 'for',\n",
       " 'concur',\n",
       " 'request,',\n",
       " \"i'm\",\n",
       " 'following',\n",
       " 'its',\n",
       " 'approval.',\n",
       " 'thanks.',\n",
       " 'regards,',\n",
       " 'm.badawy',\n",
       " '+201229165469']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class WordCloud in module wordcloud.wordcloud:\n",
      "\n",
      "class WordCloud(builtins.object)\n",
      " |  Word cloud object for generating and drawing.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  font_path : string\n",
      " |      Font path to the font that will be used (OTF or TTF).\n",
      " |      Defaults to DroidSansMono path on a Linux machine. If you are on\n",
      " |      another OS or don't have this font, you need to adjust this path.\n",
      " |  \n",
      " |  width : int (default=400)\n",
      " |      Width of the canvas.\n",
      " |  \n",
      " |  height : int (default=200)\n",
      " |      Height of the canvas.\n",
      " |  \n",
      " |  prefer_horizontal : float (default=0.90)\n",
      " |      The ratio of times to try horizontal fitting as opposed to vertical.\n",
      " |      If prefer_horizontal < 1, the algorithm will try rotating the word\n",
      " |      if it doesn't fit. (There is currently no built-in way to get only\n",
      " |      vertical words.)\n",
      " |  \n",
      " |  mask : nd-array or None (default=None)\n",
      " |      If not None, gives a binary mask on where to draw words. If mask is not\n",
      " |      None, width and height will be ignored and the shape of mask will be\n",
      " |      used instead. All white (#FF or #FFFFFF) entries will be considerd\n",
      " |      \"masked out\" while other entries will be free to draw on. [This\n",
      " |      changed in the most recent version!]\n",
      " |  \n",
      " |  contour_width: float (default=0)\n",
      " |      If mask is not None and contour_width > 0, draw the mask contour.\n",
      " |  \n",
      " |  contour_color: color value (default=\"black\")\n",
      " |      Mask contour color.\n",
      " |  \n",
      " |  scale : float (default=1)\n",
      " |      Scaling between computation and drawing. For large word-cloud images,\n",
      " |      using scale instead of larger canvas size is significantly faster, but\n",
      " |      might lead to a coarser fit for the words.\n",
      " |  \n",
      " |  min_font_size : int (default=4)\n",
      " |      Smallest font size to use. Will stop when there is no more room in this\n",
      " |      size.\n",
      " |  \n",
      " |  font_step : int (default=1)\n",
      " |      Step size for the font. font_step > 1 might speed up computation but\n",
      " |      give a worse fit.\n",
      " |  \n",
      " |  max_words : number (default=200)\n",
      " |      The maximum number of words.\n",
      " |  \n",
      " |  stopwords : set of strings or None\n",
      " |      The words that will be eliminated. If None, the build-in STOPWORDS\n",
      " |      list will be used. Ignored if using generate_from_frequencies.\n",
      " |  \n",
      " |  background_color : color value (default=\"black\")\n",
      " |      Background color for the word cloud image.\n",
      " |  \n",
      " |  max_font_size : int or None (default=None)\n",
      " |      Maximum font size for the largest word. If None, height of the image is\n",
      " |      used.\n",
      " |  \n",
      " |  mode : string (default=\"RGB\")\n",
      " |      Transparent background will be generated when mode is \"RGBA\" and\n",
      " |      background_color is None.\n",
      " |  \n",
      " |  relative_scaling : float (default='auto')\n",
      " |      Importance of relative word frequencies for font-size.  With\n",
      " |      relative_scaling=0, only word-ranks are considered.  With\n",
      " |      relative_scaling=1, a word that is twice as frequent will have twice\n",
      " |      the size.  If you want to consider the word frequencies and not only\n",
      " |      their rank, relative_scaling around .5 often looks good.\n",
      " |      If 'auto' it will be set to 0.5 unless repeat is true, in which\n",
      " |      case it will be set to 0.\n",
      " |  \n",
      " |      .. versionchanged: 2.0\n",
      " |          Default is now 'auto'.\n",
      " |  \n",
      " |  color_func : callable, default=None\n",
      " |      Callable with parameters word, font_size, position, orientation,\n",
      " |      font_path, random_state that returns a PIL color for each word.\n",
      " |      Overwrites \"colormap\".\n",
      " |      See colormap for specifying a matplotlib colormap instead.\n",
      " |      To create a word cloud with a single color, use\n",
      " |      ``color_func=lambda *args, **kwargs: \"white\"``.\n",
      " |      The single color can also be specified using RGB code. For example\n",
      " |      ``color_func=lambda *args, **kwargs: (255,0,0)`` sets color to red.\n",
      " |  \n",
      " |  regexp : string or None (optional)\n",
      " |      Regular expression to split the input text into tokens in process_text.\n",
      " |      If None is specified, ``r\"\\w[\\w']+\"`` is used. Ignored if using\n",
      " |      generate_from_frequencies.\n",
      " |  \n",
      " |  collocations : bool, default=True\n",
      " |      Whether to include collocations (bigrams) of two words. Ignored if using\n",
      " |      generate_from_frequencies.\n",
      " |  \n",
      " |  \n",
      " |      .. versionadded: 2.0\n",
      " |  \n",
      " |  colormap : string or matplotlib colormap, default=\"viridis\"\n",
      " |      Matplotlib colormap to randomly draw colors from for each word.\n",
      " |      Ignored if \"color_func\" is specified.\n",
      " |  \n",
      " |      .. versionadded: 2.0\n",
      " |  \n",
      " |  normalize_plurals : bool, default=True\n",
      " |      Whether to remove trailing 's' from words. If True and a word\n",
      " |      appears with and without a trailing 's', the one with trailing 's'\n",
      " |      is removed and its counts are added to the version without\n",
      " |      trailing 's' -- unless the word ends with 'ss'. Ignored if using\n",
      " |      generate_from_frequencies.\n",
      " |  \n",
      " |  repeat : bool, default=False\n",
      " |      Whether to repeat words and phrases until max_words or min_font_size\n",
      " |      is reached.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  ``words_`` : dict of string to float\n",
      " |      Word tokens with associated frequency.\n",
      " |  \n",
      " |      .. versionchanged: 2.0\n",
      " |          ``words_`` is now a dictionary\n",
      " |  \n",
      " |  ``layout_`` : list of tuples (string, int, (int, int), int, color))\n",
      " |      Encodes the fitted word cloud. Encodes for each word the string, font\n",
      " |      size, position, orientation and color.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Larger canvases with make the code significantly slower. If you need a\n",
      " |  large word cloud, try a lower canvas size, and set the scale parameter.\n",
      " |  \n",
      " |  The algorithm might give more weight to the ranking of the words\n",
      " |  than their actual frequencies, depending on the ``max_font_size`` and the\n",
      " |  scaling heuristic.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __array__(self)\n",
      " |      Convert to numpy array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      image : nd-array size (width, height, 3)\n",
      " |          Word cloud image as numpy matrix.\n",
      " |  \n",
      " |  __init__(self, font_path=None, width=400, height=200, margin=2, ranks_only=None, prefer_horizontal=0.9, mask=None, scale=1, color_func=None, max_words=200, min_font_size=4, stopwords=None, random_state=None, background_color='black', max_font_size=None, font_step=1, mode='RGB', relative_scaling='auto', regexp=None, collocations=True, colormap=None, normalize_plurals=True, contour_width=0, contour_color='black', repeat=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit_words(self, frequencies)\n",
      " |      Create a word_cloud from words and frequencies.\n",
      " |      \n",
      " |      Alias to generate_from_frequencies.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frequencies : dict from string to float\n",
      " |          A contains words and associated frequency.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  generate(self, text)\n",
      " |      Generate wordcloud from text.\n",
      " |      \n",
      " |      The input \"text\" is expected to be a natural text. If you pass a sorted\n",
      " |      list of words, words will appear in your output twice. To remove this\n",
      " |      duplication, set ``collocations=False``.\n",
      " |      \n",
      " |      Alias to generate_from_text.\n",
      " |      \n",
      " |      Calls process_text and generate_from_frequencies.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  generate_from_frequencies(self, frequencies, max_font_size=None)\n",
      " |      Create a word_cloud from words and frequencies.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frequencies : dict from string to float\n",
      " |          A contains words and associated frequency.\n",
      " |      \n",
      " |      max_font_size : int\n",
      " |          Use this font-size instead of self.max_font_size\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  generate_from_text(self, text)\n",
      " |      Generate wordcloud from text.\n",
      " |      \n",
      " |      The input \"text\" is expected to be a natural text. If you pass a sorted\n",
      " |      list of words, words will appear in your output twice. To remove this\n",
      " |      duplication, set ``collocations=False``.\n",
      " |      \n",
      " |      Calls process_text and generate_from_frequencies.\n",
      " |      \n",
      " |      ..versionchanged:: 1.2.2\n",
      " |          Argument of generate_from_frequencies() is not return of\n",
      " |          process_text() any more.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  process_text(self, text)\n",
      " |      Splits a long text into words, eliminates the stopwords.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      text : string\n",
      " |          The text to be processed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      words : dict (string, int)\n",
      " |          Word tokens with associated frequency.\n",
      " |      \n",
      " |      ..versionchanged:: 1.2.2\n",
      " |          Changed return type from list of tuples to dict.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      There are better ways to do word tokenization, but I don't want to\n",
      " |      include all those things.\n",
      " |  \n",
      " |  recolor(self, random_state=None, color_func=None, colormap=None)\n",
      " |      Recolor existing layout.\n",
      " |      \n",
      " |      Applying a new coloring is much faster than generating the whole\n",
      " |      wordcloud.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      random_state : RandomState, int, or None, default=None\n",
      " |          If not None, a fixed random state is used. If an int is given, this\n",
      " |          is used as seed for a random.Random state.\n",
      " |      \n",
      " |      color_func : function or None, default=None\n",
      " |          Function to generate new color from word count, font size, position\n",
      " |          and orientation.  If None, self.color_func is used.\n",
      " |      \n",
      " |      colormap : string or matplotlib colormap, default=None\n",
      " |          Use this colormap to generate new colors. Ignored if color_func\n",
      " |          is specified. If None, self.color_func (or self.color_map) is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  to_array(self)\n",
      " |      Convert to numpy array.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      image : nd-array size (width, height, 3)\n",
      " |          Word cloud image as numpy matrix.\n",
      " |  \n",
      " |  to_file(self, filename)\n",
      " |      Export to image file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : string\n",
      " |          Location to write to.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  to_html(self)\n",
      " |  \n",
      " |  to_image(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(WordCloud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordcloud.wordcloud.WordCloud"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class WordCloud(object):\n",
      "    r\"\"\"Word cloud object for generating and drawing.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    font_path : string\n",
      "        Font path to the font that will be used (OTF or TTF).\n",
      "        Defaults to DroidSansMono path on a Linux machine. If you are on\n",
      "        another OS or don't have this font, you need to adjust this path.\n",
      "\n",
      "    width : int (default=400)\n",
      "        Width of the canvas.\n",
      "\n",
      "    height : int (default=200)\n",
      "        Height of the canvas.\n",
      "\n",
      "    prefer_horizontal : float (default=0.90)\n",
      "        The ratio of times to try horizontal fitting as opposed to vertical.\n",
      "        If prefer_horizontal < 1, the algorithm will try rotating the word\n",
      "        if it doesn't fit. (There is currently no built-in way to get only\n",
      "        vertical words.)\n",
      "\n",
      "    mask : nd-array or None (default=None)\n",
      "        If not None, gives a binary mask on where to draw words. If mask is not\n",
      "        None, width and height will be ignored and the shape of mask will be\n",
      "        used instead. All white (#FF or #FFFFFF) entries will be considerd\n",
      "        \"masked out\" while other entries will be free to draw on. [This\n",
      "        changed in the most recent version!]\n",
      "\n",
      "    contour_width: float (default=0)\n",
      "        If mask is not None and contour_width > 0, draw the mask contour.\n",
      "\n",
      "    contour_color: color value (default=\"black\")\n",
      "        Mask contour color.\n",
      "\n",
      "    scale : float (default=1)\n",
      "        Scaling between computation and drawing. For large word-cloud images,\n",
      "        using scale instead of larger canvas size is significantly faster, but\n",
      "        might lead to a coarser fit for the words.\n",
      "\n",
      "    min_font_size : int (default=4)\n",
      "        Smallest font size to use. Will stop when there is no more room in this\n",
      "        size.\n",
      "\n",
      "    font_step : int (default=1)\n",
      "        Step size for the font. font_step > 1 might speed up computation but\n",
      "        give a worse fit.\n",
      "\n",
      "    max_words : number (default=200)\n",
      "        The maximum number of words.\n",
      "\n",
      "    stopwords : set of strings or None\n",
      "        The words that will be eliminated. If None, the build-in STOPWORDS\n",
      "        list will be used. Ignored if using generate_from_frequencies.\n",
      "\n",
      "    background_color : color value (default=\"black\")\n",
      "        Background color for the word cloud image.\n",
      "\n",
      "    max_font_size : int or None (default=None)\n",
      "        Maximum font size for the largest word. If None, height of the image is\n",
      "        used.\n",
      "\n",
      "    mode : string (default=\"RGB\")\n",
      "        Transparent background will be generated when mode is \"RGBA\" and\n",
      "        background_color is None.\n",
      "\n",
      "    relative_scaling : float (default='auto')\n",
      "        Importance of relative word frequencies for font-size.  With\n",
      "        relative_scaling=0, only word-ranks are considered.  With\n",
      "        relative_scaling=1, a word that is twice as frequent will have twice\n",
      "        the size.  If you want to consider the word frequencies and not only\n",
      "        their rank, relative_scaling around .5 often looks good.\n",
      "        If 'auto' it will be set to 0.5 unless repeat is true, in which\n",
      "        case it will be set to 0.\n",
      "\n",
      "        .. versionchanged: 2.0\n",
      "            Default is now 'auto'.\n",
      "\n",
      "    color_func : callable, default=None\n",
      "        Callable with parameters word, font_size, position, orientation,\n",
      "        font_path, random_state that returns a PIL color for each word.\n",
      "        Overwrites \"colormap\".\n",
      "        See colormap for specifying a matplotlib colormap instead.\n",
      "        To create a word cloud with a single color, use\n",
      "        ``color_func=lambda *args, **kwargs: \"white\"``.\n",
      "        The single color can also be specified using RGB code. For example\n",
      "        ``color_func=lambda *args, **kwargs: (255,0,0)`` sets color to red.\n",
      "\n",
      "    regexp : string or None (optional)\n",
      "        Regular expression to split the input text into tokens in process_text.\n",
      "        If None is specified, ``r\"\\w[\\w']+\"`` is used. Ignored if using\n",
      "        generate_from_frequencies.\n",
      "\n",
      "    collocations : bool, default=True\n",
      "        Whether to include collocations (bigrams) of two words. Ignored if using\n",
      "        generate_from_frequencies.\n",
      "\n",
      "\n",
      "        .. versionadded: 2.0\n",
      "\n",
      "    colormap : string or matplotlib colormap, default=\"viridis\"\n",
      "        Matplotlib colormap to randomly draw colors from for each word.\n",
      "        Ignored if \"color_func\" is specified.\n",
      "\n",
      "        .. versionadded: 2.0\n",
      "\n",
      "    normalize_plurals : bool, default=True\n",
      "        Whether to remove trailing 's' from words. If True and a word\n",
      "        appears with and without a trailing 's', the one with trailing 's'\n",
      "        is removed and its counts are added to the version without\n",
      "        trailing 's' -- unless the word ends with 'ss'. Ignored if using\n",
      "        generate_from_frequencies.\n",
      "\n",
      "    repeat : bool, default=False\n",
      "        Whether to repeat words and phrases until max_words or min_font_size\n",
      "        is reached.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    ``words_`` : dict of string to float\n",
      "        Word tokens with associated frequency.\n",
      "\n",
      "        .. versionchanged: 2.0\n",
      "            ``words_`` is now a dictionary\n",
      "\n",
      "    ``layout_`` : list of tuples (string, int, (int, int), int, color))\n",
      "        Encodes the fitted word cloud. Encodes for each word the string, font\n",
      "        size, position, orientation and color.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Larger canvases with make the code significantly slower. If you need a\n",
      "    large word cloud, try a lower canvas size, and set the scale parameter.\n",
      "\n",
      "    The algorithm might give more weight to the ranking of the words\n",
      "    than their actual frequencies, depending on the ``max_font_size`` and the\n",
      "    scaling heuristic.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, font_path=None, width=400, height=200, margin=2,\n",
      "                 ranks_only=None, prefer_horizontal=.9, mask=None, scale=1,\n",
      "                 color_func=None, max_words=200, min_font_size=4,\n",
      "                 stopwords=None, random_state=None, background_color='black',\n",
      "                 max_font_size=None, font_step=1, mode=\"RGB\",\n",
      "                 relative_scaling='auto', regexp=None, collocations=True,\n",
      "                 colormap=None, normalize_plurals=True, contour_width=0,\n",
      "                 contour_color='black', repeat=False):\n",
      "        if font_path is None:\n",
      "            font_path = FONT_PATH\n",
      "        if color_func is None and colormap is None:\n",
      "            # we need a color map\n",
      "            import matplotlib\n",
      "            version = matplotlib.__version__\n",
      "            if version[0] < \"2\" and version[2] < \"5\":\n",
      "                colormap = \"hsv\"\n",
      "            else:\n",
      "                colormap = \"viridis\"\n",
      "        self.colormap = colormap\n",
      "        self.collocations = collocations\n",
      "        self.font_path = font_path\n",
      "        self.width = width\n",
      "        self.height = height\n",
      "        self.margin = margin\n",
      "        self.prefer_horizontal = prefer_horizontal\n",
      "        self.mask = mask\n",
      "        self.contour_color = contour_color\n",
      "        self.contour_width = contour_width\n",
      "        self.scale = scale\n",
      "        self.color_func = color_func or colormap_color_func(colormap)\n",
      "        self.max_words = max_words\n",
      "        self.stopwords = stopwords if stopwords is not None else STOPWORDS\n",
      "        self.min_font_size = min_font_size\n",
      "        self.font_step = font_step\n",
      "        self.regexp = regexp\n",
      "        if isinstance(random_state, int):\n",
      "            random_state = Random(random_state)\n",
      "        self.random_state = random_state\n",
      "        self.background_color = background_color\n",
      "        self.max_font_size = max_font_size\n",
      "        self.mode = mode\n",
      "\n",
      "        if relative_scaling == \"auto\":\n",
      "            if repeat:\n",
      "                relative_scaling = 0\n",
      "            else:\n",
      "                relative_scaling = .5\n",
      "\n",
      "        if relative_scaling < 0 or relative_scaling > 1:\n",
      "            raise ValueError(\"relative_scaling needs to be \"\n",
      "                             \"between 0 and 1, got %f.\" % relative_scaling)\n",
      "        self.relative_scaling = relative_scaling\n",
      "        if ranks_only is not None:\n",
      "            warnings.warn(\"ranks_only is deprecated and will be removed as\"\n",
      "                          \" it had no effect. Look into relative_scaling.\",\n",
      "                          DeprecationWarning)\n",
      "        self.normalize_plurals = normalize_plurals\n",
      "        self.repeat = repeat\n",
      "\n",
      "    def fit_words(self, frequencies):\n",
      "        \"\"\"Create a word_cloud from words and frequencies.\n",
      "\n",
      "        Alias to generate_from_frequencies.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        frequencies : dict from string to float\n",
      "            A contains words and associated frequency.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "        \"\"\"\n",
      "        return self.generate_from_frequencies(frequencies)\n",
      "\n",
      "    def generate_from_frequencies(self, frequencies, max_font_size=None):  # noqa: C901\n",
      "        \"\"\"Create a word_cloud from words and frequencies.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        frequencies : dict from string to float\n",
      "            A contains words and associated frequency.\n",
      "\n",
      "        max_font_size : int\n",
      "            Use this font-size instead of self.max_font_size\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "\n",
      "        \"\"\"\n",
      "        # make sure frequencies are sorted and normalized\n",
      "        frequencies = sorted(frequencies.items(), key=itemgetter(1), reverse=True)\n",
      "        if len(frequencies) <= 0:\n",
      "            raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n",
      "                             \"got %d.\" % len(frequencies))\n",
      "        frequencies = frequencies[:self.max_words]\n",
      "\n",
      "        # largest entry will be 1\n",
      "        max_frequency = float(frequencies[0][1])\n",
      "\n",
      "        frequencies = [(word, freq / max_frequency)\n",
      "                       for word, freq in frequencies]\n",
      "\n",
      "        if self.random_state is not None:\n",
      "            random_state = self.random_state\n",
      "        else:\n",
      "            random_state = Random()\n",
      "\n",
      "        if self.mask is not None:\n",
      "            boolean_mask = self._get_bolean_mask(self.mask)\n",
      "            width = self.mask.shape[1]\n",
      "            height = self.mask.shape[0]\n",
      "        else:\n",
      "            boolean_mask = None\n",
      "            height, width = self.height, self.width\n",
      "        occupancy = IntegralOccupancyMap(height, width, boolean_mask)\n",
      "\n",
      "        # create image\n",
      "        img_grey = Image.new(\"L\", (width, height))\n",
      "        draw = ImageDraw.Draw(img_grey)\n",
      "        img_array = np.asarray(img_grey)\n",
      "        font_sizes, positions, orientations, colors = [], [], [], []\n",
      "\n",
      "        last_freq = 1.\n",
      "\n",
      "        if max_font_size is None:\n",
      "            # if not provided use default font_size\n",
      "            max_font_size = self.max_font_size\n",
      "\n",
      "        if max_font_size is None:\n",
      "            # figure out a good font size by trying to draw with\n",
      "            # just the first two words\n",
      "            if len(frequencies) == 1:\n",
      "                # we only have one word. We make it big!\n",
      "                font_size = self.height\n",
      "            else:\n",
      "                self.generate_from_frequencies(dict(frequencies[:2]),\n",
      "                                               max_font_size=self.height)\n",
      "                # find font sizes\n",
      "                sizes = [x[1] for x in self.layout_]\n",
      "                try:\n",
      "                    font_size = int(2 * sizes[0] * sizes[1]\n",
      "                                    / (sizes[0] + sizes[1]))\n",
      "                # quick fix for if self.layout_ contains less than 2 values\n",
      "                # on very small images it can be empty\n",
      "                except IndexError:\n",
      "                    try:\n",
      "                        font_size = sizes[0]\n",
      "                    except IndexError:\n",
      "                        raise ValueError(\n",
      "                            \"Couldn't find space to draw. Either the Canvas size\"\n",
      "                            \" is too small or too much of the image is masked \"\n",
      "                            \"out.\")\n",
      "        else:\n",
      "            font_size = max_font_size\n",
      "\n",
      "        # we set self.words_ here because we called generate_from_frequencies\n",
      "        # above... hurray for good design?\n",
      "        self.words_ = dict(frequencies)\n",
      "\n",
      "        if self.repeat and len(frequencies) < self.max_words:\n",
      "            # pad frequencies with repeating words.\n",
      "            times_extend = int(np.ceil(self.max_words / len(frequencies))) - 1\n",
      "            # get smallest frequency\n",
      "            frequencies_org = list(frequencies)\n",
      "            downweight = frequencies[-1][1]\n",
      "            for i in range(times_extend):\n",
      "                frequencies.extend([(word, freq * downweight ** (i + 1))\n",
      "                                    for word, freq in frequencies_org])\n",
      "\n",
      "        # start drawing grey image\n",
      "        for word, freq in frequencies:\n",
      "            # select the font size\n",
      "            rs = self.relative_scaling\n",
      "            if rs != 0:\n",
      "                font_size = int(round((rs * (freq / float(last_freq))\n",
      "                                       + (1 - rs)) * font_size))\n",
      "            if random_state.random() < self.prefer_horizontal:\n",
      "                orientation = None\n",
      "            else:\n",
      "                orientation = Image.ROTATE_90\n",
      "            tried_other_orientation = False\n",
      "            while True:\n",
      "                # try to find a position\n",
      "                font = ImageFont.truetype(self.font_path, font_size)\n",
      "                # transpose font optionally\n",
      "                transposed_font = ImageFont.TransposedFont(\n",
      "                    font, orientation=orientation)\n",
      "                # get size of resulting text\n",
      "                box_size = draw.textsize(word, font=transposed_font)\n",
      "                # find possible places using integral image:\n",
      "                result = occupancy.sample_position(box_size[1] + self.margin,\n",
      "                                                   box_size[0] + self.margin,\n",
      "                                                   random_state)\n",
      "                if result is not None or font_size < self.min_font_size:\n",
      "                    # either we found a place or font-size went too small\n",
      "                    break\n",
      "                # if we didn't find a place, make font smaller\n",
      "                # but first try to rotate!\n",
      "                if not tried_other_orientation and self.prefer_horizontal < 1:\n",
      "                    orientation = (Image.ROTATE_90 if orientation is None else\n",
      "                                   Image.ROTATE_90)\n",
      "                    tried_other_orientation = True\n",
      "                else:\n",
      "                    font_size -= self.font_step\n",
      "                    orientation = None\n",
      "\n",
      "            if font_size < self.min_font_size:\n",
      "                # we were unable to draw any more\n",
      "                break\n",
      "\n",
      "            x, y = np.array(result) + self.margin // 2\n",
      "            # actually draw the text\n",
      "            draw.text((y, x), word, fill=\"white\", font=transposed_font)\n",
      "            positions.append((x, y))\n",
      "            orientations.append(orientation)\n",
      "            font_sizes.append(font_size)\n",
      "            colors.append(self.color_func(word, font_size=font_size,\n",
      "                                          position=(x, y),\n",
      "                                          orientation=orientation,\n",
      "                                          random_state=random_state,\n",
      "                                          font_path=self.font_path))\n",
      "            # recompute integral image\n",
      "            if self.mask is None:\n",
      "                img_array = np.asarray(img_grey)\n",
      "            else:\n",
      "                img_array = np.asarray(img_grey) + boolean_mask\n",
      "            # recompute bottom right\n",
      "            # the order of the cumsum's is important for speed ?!\n",
      "            occupancy.update(img_array, x, y)\n",
      "            last_freq = freq\n",
      "\n",
      "        self.layout_ = list(zip(frequencies, font_sizes, positions,\n",
      "                                orientations, colors))\n",
      "        return self\n",
      "\n",
      "    def process_text(self, text):\n",
      "        \"\"\"Splits a long text into words, eliminates the stopwords.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        text : string\n",
      "            The text to be processed.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        words : dict (string, int)\n",
      "            Word tokens with associated frequency.\n",
      "\n",
      "        ..versionchanged:: 1.2.2\n",
      "            Changed return type from list of tuples to dict.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        There are better ways to do word tokenization, but I don't want to\n",
      "        include all those things.\n",
      "        \"\"\"\n",
      "\n",
      "        stopwords = set([i.lower() for i in self.stopwords])\n",
      "\n",
      "        flags = (re.UNICODE if sys.version < '3' and type(text) is unicode  # noqa: F821\n",
      "                 else 0)\n",
      "        regexp = self.regexp if self.regexp is not None else r\"\\w[\\w']+\"\n",
      "\n",
      "        words = re.findall(regexp, text, flags)\n",
      "        # remove stopwords\n",
      "        words = [word for word in words if word.lower() not in stopwords]\n",
      "        # remove 's\n",
      "        words = [word[:-2] if word.lower().endswith(\"'s\") else word\n",
      "                 for word in words]\n",
      "        # remove numbers\n",
      "        words = [word for word in words if not word.isdigit()]\n",
      "\n",
      "        if self.collocations:\n",
      "            word_counts = unigrams_and_bigrams(words, self.normalize_plurals)\n",
      "        else:\n",
      "            word_counts, _ = process_tokens(words, self.normalize_plurals)\n",
      "\n",
      "        return word_counts\n",
      "\n",
      "    def generate_from_text(self, text):\n",
      "        \"\"\"Generate wordcloud from text.\n",
      "\n",
      "        The input \"text\" is expected to be a natural text. If you pass a sorted\n",
      "        list of words, words will appear in your output twice. To remove this\n",
      "        duplication, set ``collocations=False``.\n",
      "\n",
      "        Calls process_text and generate_from_frequencies.\n",
      "\n",
      "        ..versionchanged:: 1.2.2\n",
      "            Argument of generate_from_frequencies() is not return of\n",
      "            process_text() any more.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "        \"\"\"\n",
      "        words = self.process_text(text)\n",
      "        self.generate_from_frequencies(words)\n",
      "        return self\n",
      "\n",
      "    def generate(self, text):\n",
      "        \"\"\"Generate wordcloud from text.\n",
      "\n",
      "        The input \"text\" is expected to be a natural text. If you pass a sorted\n",
      "        list of words, words will appear in your output twice. To remove this\n",
      "        duplication, set ``collocations=False``.\n",
      "\n",
      "        Alias to generate_from_text.\n",
      "\n",
      "        Calls process_text and generate_from_frequencies.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "        \"\"\"\n",
      "        return self.generate_from_text(text)\n",
      "\n",
      "    def _check_generated(self):\n",
      "        \"\"\"Check if ``layout_`` was computed, otherwise raise error.\"\"\"\n",
      "        if not hasattr(self, \"layout_\"):\n",
      "            raise ValueError(\"WordCloud has not been calculated, call generate\"\n",
      "                             \" first.\")\n",
      "\n",
      "    def to_image(self):\n",
      "        self._check_generated()\n",
      "        if self.mask is not None:\n",
      "            width = self.mask.shape[1]\n",
      "            height = self.mask.shape[0]\n",
      "        else:\n",
      "            height, width = self.height, self.width\n",
      "\n",
      "        img = Image.new(self.mode, (int(width * self.scale),\n",
      "                                    int(height * self.scale)),\n",
      "                        self.background_color)\n",
      "        draw = ImageDraw.Draw(img)\n",
      "        for (word, count), font_size, position, orientation, color in self.layout_:\n",
      "            font = ImageFont.truetype(self.font_path,\n",
      "                                      int(font_size * self.scale))\n",
      "            transposed_font = ImageFont.TransposedFont(\n",
      "                font, orientation=orientation)\n",
      "            pos = (int(position[1] * self.scale),\n",
      "                   int(position[0] * self.scale))\n",
      "            draw.text(pos, word, fill=color, font=transposed_font)\n",
      "\n",
      "        return self._draw_contour(img=img)\n",
      "\n",
      "    def recolor(self, random_state=None, color_func=None, colormap=None):\n",
      "        \"\"\"Recolor existing layout.\n",
      "\n",
      "        Applying a new coloring is much faster than generating the whole\n",
      "        wordcloud.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        random_state : RandomState, int, or None, default=None\n",
      "            If not None, a fixed random state is used. If an int is given, this\n",
      "            is used as seed for a random.Random state.\n",
      "\n",
      "        color_func : function or None, default=None\n",
      "            Function to generate new color from word count, font size, position\n",
      "            and orientation.  If None, self.color_func is used.\n",
      "\n",
      "        colormap : string or matplotlib colormap, default=None\n",
      "            Use this colormap to generate new colors. Ignored if color_func\n",
      "            is specified. If None, self.color_func (or self.color_map) is used.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "        \"\"\"\n",
      "        if isinstance(random_state, int):\n",
      "            random_state = Random(random_state)\n",
      "        self._check_generated()\n",
      "\n",
      "        if color_func is None:\n",
      "            if colormap is None:\n",
      "                color_func = self.color_func\n",
      "            else:\n",
      "                color_func = colormap_color_func(colormap)\n",
      "        self.layout_ = [(word_freq, font_size, position, orientation,\n",
      "                         color_func(word=word_freq[0], font_size=font_size,\n",
      "                                    position=position, orientation=orientation,\n",
      "                                    random_state=random_state,\n",
      "                                    font_path=self.font_path))\n",
      "                        for word_freq, font_size, position, orientation, _\n",
      "                        in self.layout_]\n",
      "        return self\n",
      "\n",
      "    def to_file(self, filename):\n",
      "        \"\"\"Export to image file.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : string\n",
      "            Location to write to.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self\n",
      "        \"\"\"\n",
      "\n",
      "        img = self.to_image()\n",
      "        img.save(filename, optimize=True)\n",
      "        return self\n",
      "\n",
      "    def to_array(self):\n",
      "        \"\"\"Convert to numpy array.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        image : nd-array size (width, height, 3)\n",
      "            Word cloud image as numpy matrix.\n",
      "        \"\"\"\n",
      "        return np.array(self.to_image())\n",
      "\n",
      "    def __array__(self):\n",
      "        \"\"\"Convert to numpy array.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        image : nd-array size (width, height, 3)\n",
      "            Word cloud image as numpy matrix.\n",
      "        \"\"\"\n",
      "        return self.to_array()\n",
      "\n",
      "    def to_html(self):\n",
      "        raise NotImplementedError(\"FIXME!!!\")\n",
      "\n",
      "    def _get_bolean_mask(self, mask):\n",
      "        \"\"\"Cast to two dimensional boolean mask.\"\"\"\n",
      "        if mask.dtype.kind == 'f':\n",
      "            warnings.warn(\"mask image should be unsigned byte between 0\"\n",
      "                          \" and 255. Got a float array\")\n",
      "        if mask.ndim == 2:\n",
      "            boolean_mask = mask == 255\n",
      "        elif mask.ndim == 3:\n",
      "            # if all channels are white, mask out\n",
      "            boolean_mask = np.all(mask[:, :, :3] == 255, axis=-1)\n",
      "        else:\n",
      "            raise ValueError(\"Got mask of invalid shape: %s\" % str(mask.shape))\n",
      "        return boolean_mask\n",
      "\n",
      "    def _draw_contour(self, img):\n",
      "        \"\"\"Draw mask contour on a pillow image.\"\"\"\n",
      "        if self.mask is None or self.contour_width == 0:\n",
      "            return img\n",
      "\n",
      "        mask = self._get_bolean_mask(self.mask) * 255\n",
      "        contour = Image.fromarray(mask.astype(np.uint8))\n",
      "        contour = contour.resize(img.size)\n",
      "        contour = contour.filter(ImageFilter.FIND_EDGES)\n",
      "        contour = np.array(contour)\n",
      "\n",
      "        # make sure borders are not drawn before changing width\n",
      "        contour[[0, -1], :] = 0\n",
      "        contour[:, [0, -1]] = 0\n",
      "\n",
      "        # use gaussian to change width, divide by 10 to give more resolution\n",
      "        radius = self.contour_width / 10\n",
      "        contour = Image.fromarray(contour)\n",
      "        contour = contour.filter(ImageFilter.GaussianBlur(radius=radius))\n",
      "        contour = np.array(contour) > 0\n",
      "        contour = np.dstack((contour, contour, contour))\n",
      "\n",
      "        # color the contour\n",
      "        ret = np.array(img) * np.invert(contour)\n",
      "        if self.contour_color != 'black':\n",
      "            color = Image.new(img.mode, img.size, self.contour_color)\n",
      "            ret += np.array(color) * contour\n",
      "\n",
      "        return Image.fromarray(ret)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "lines = inspect.getsource(WordCloud)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Record Locator : HQGWCY - Release tickets: Tra...\n",
       "1        Record Locator : ZNUPUE - Release tickets: Tra...\n",
       "2        Release tickets: Travel approved to TAS Securi...\n",
       "3        Release tickets: Travel approved to TAS Securi...\n",
       "4        Record Locator : DXERDW - Release tickets: Tra...\n",
       "5        SBU Report -  - AccentureMultilocationPolicy  ...\n",
       "6        Purchase Order Number 4200988011  Please find ...\n",
       "7        RE: Re: Re: Booking of Request MMCG for Rohit ...\n",
       "8        RE: Booking of Request MPDR for Dinabandhu Mon...\n",
       "9        Reservation Confirmation #70064628 for TownePl...\n",
       "10       é\n",
       "åºé¢è®¢ç¡®è®¤å,A253R3W, QIAN YING, ä¸æ...\n",
       "11       é\n",
       "åºé¢è®¢ç¡®è®¤å,A253R3W, QIAN YING, ä¸æ...\n",
       "12       change flight enquire  Hi there,\\n\\nPlease fin...\n",
       "13       Mr Theodoros NOUTSOS and Ms Sarah Pai Wah DAI ...\n",
       "14       Below trip needs your approval[10276489][wu.zh...\n",
       "15       El Paseo Limousine - 24 Hour Advanced Confirma...\n",
       "16       KAOHSIUNG AND TOKYO  Hi Josephine\\n\\nI have be...\n",
       "17       RE: Trip document (e-ticket receipt) for Ms Lo...\n",
       "18       Further change - Trip for Mr Mark Alan COXON o...\n",
       "19       Carey Service Reminder for Richard Jewell  for...\n",
       "20       RE: URGENT Approval Needed 31997 <<#2359130-65...\n",
       "21       FW: Trip document (e-ticket receipt) for Ms Gi...\n",
       "22       RE: International Travel Request: Hilary C. E....\n",
       "23       Survey Response Received: Customer Oracle (Ind...\n",
       "24       Comments: Survey Response Received: From India...\n",
       "25       CWT LISTENS 9 to 10 COMPLIMENTS:  INDIA  ORACL...\n",
       "26       IR 15000995 [Production; Rejected; Medium]: Am...\n",
       "27       IR 15189563 [Production; Rejected; Medium]: Am...\n",
       "28       System Notification: The application TRCCCQD18...\n",
       "29       Re:  RE: Carey Service Reminder for Richard Je...\n",
       "                               ...                        \n",
       "28840    Flight tickets from Delhi to Pune <<#1027898-5...\n",
       "28841    RE: DeepakTripathi_Travel Request_6Jul Jun {{:...\n",
       "28842    RE: FW: Reserva a MEX 30JUN <<#2732132-6507997...\n",
       "28843    CHANGE OF RETURN TKT TO 07.07.18N Mrs Andrea M...\n",
       "28844    RE: Approval of Request 43LYJ for Ravindra Mat...\n",
       "28845    RE: Re: Trip itinerary for Mr Suwalit CHOOPREE...\n",
       "28846    Action Required: Capital One Welcomes Dennis L...\n",
       "28847    Travel Document for: MAURICIO DR SUBIETA - Tra...\n",
       "28848    Travel Document for: AEKANG KAY HONG - Travel ...\n",
       "28849    Travel Document for: JOSEPH ADEREMI ADEYEMI - ...\n",
       "28850    Travel Document for: MARK E GRIMES - Travel Da...\n",
       "28851    Travel Document for: SHARON D LARKIN - Travel ...\n",
       "28852    Travel Document for: MICHAEL ARTHUR RAFFERTY -...\n",
       "28853    Travel Document for: FRANK M TERLIZZI - Travel...\n",
       "28854    Travel Document for: PASCHAL OGE MAFIANA - Tra...\n",
       "28855    Travel Document for: ESIMAJE ONORITSEBAWOR BRI...\n",
       "28856    Travel Document for: LAURA DULA - Travel Date:...\n",
       "28857    Travel Document for: JEFF ALAN BRUNNER - Trave...\n",
       "28858    Travel Document for: PASCHAL OGE MAFIANA - Tra...\n",
       "28859    Travel Document for: LESLIE LENETTE ALLEN - Tr...\n",
       "28860    Travel Document for: FRANCOIS MR MELLET - Trav...\n",
       "28861    Travel Document for: SHARON D LARKIN - Travel ...\n",
       "28862    Itin For MATTHEW LAWRENCE HOWARTH 26JUN  **Do ...\n",
       "28863    Travel Document for: JANET A ENGLUND - Travel ...\n",
       "28864    Travel Document for: MICAH MR WILSON - Travel ...\n",
       "28865    Travel to Mont Joli  Hi,\\n\\nI will be travelli...\n",
       "28866    Your Case 11955443 Has Been Updated (Subj: Dou...\n",
       "28867    ##6881396# COPA AIRLINES   Dear Mrs. Perez Gre...\n",
       "28868    Travel Reservation to BRUXELLES MIDI on July 0...\n",
       "28869    RE: MAL#1453 - Mohamed El Badawy - Mali <<#309...\n",
       "Name: text, Length: 28870, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regular Expression\n",
    "items = re.findall(\"([0-9]+).*: (.*)\", \"data.text\")\n",
    "\n",
    "#print items\n",
    "\n",
    "print(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-463462bf1df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",* *\\w: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/re.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(pattern, string, maxsplit, flags)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     of the list.\"\"\"\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "lines = data\n",
    "items = re.findall(\"([0-9]+).*: (.*)\", \"data.text\")\n",
    "\n",
    "#print items\n",
    "\n",
    "print(items)\n",
    "for line in lines:\n",
    "    re.split(\",* *\\w: \",line) [1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "items = re.findall(\"([0-9]+).*: (.*)\", \"data.text\")\n",
    "\n",
    "#print items\n",
    "\n",
    "print(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "items = re.findall(\"([0-9]+).*: (.*)\", \"data.text\")\n",
    "\n",
    "#print items\n",
    "\n",
    "print(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= [data.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-f52dadb480f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = ','.join(map(str, data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0        Record Locator : HQGWCY - Release tickets: Tra...\\n1        Record Locator : ZNUPUE - Release tickets: Tra...\\n2        Release tickets: Travel approved to TAS Securi...\\n3        Release tickets: Travel approved to TAS Securi...\\n4        Record Locator : DXERDW - Release tickets: Tra...\\n5        SBU Report -  - AccentureMultilocationPolicy  ...\\n6        Purchase Order Number 4200988011  Please find ...\\n7        RE: Re: Re: Booking of Request MMCG for Rohit ...\\n8        RE: Booking of Request MPDR for Dinabandhu Mon...\\n9        Reservation Confirmation #70064628 for TownePl...\\n10       é\\x85\\x92åº\\x97é¢\\x84è®¢ç¡®è®¤å\\x8d\\x95,A253R3W, QIAN YING, ä¸\\x8aæ...\\n11       é\\x85\\x92åº\\x97é¢\\x84è®¢ç¡®è®¤å\\x8d\\x95,A253R3W, QIAN YING, ä¸\\x8aæ...\\n12       change flight enquire  Hi there,\\\\n\\\\nPlease fin...\\n13       Mr Theodoros NOUTSOS and Ms Sarah Pai Wah DAI ...\\n14       Below trip needs your approval[10276489][wu.zh...\\n15       El Paseo Limousine - 24 Hour Advanced Confirma...\\n16       KAOHSIUNG AND TOKYO  Hi Josephine\\\\n\\\\nI have be...\\n17       RE: Trip document (e-ticket receipt) for Ms Lo...\\n18       Further change - Trip for Mr Mark Alan COXON o...\\n19       Carey Service Reminder for Richard Jewell  for...\\n20       RE: URGENT Approval Needed 31997 <<#2359130-65...\\n21       FW: Trip document (e-ticket receipt) for Ms Gi...\\n22       RE: International Travel Request: Hilary C. E....\\n23       Survey Response Received: Customer Oracle (Ind...\\n24       Comments: Survey Response Received: From India...\\n25       CWT LISTENS 9 to 10 COMPLIMENTS:  INDIA  ORACL...\\n26       IR 15000995 [Production; Rejected; Medium]: Am...\\n27       IR 15189563 [Production; Rejected; Medium]: Am...\\n28       System Notification: The application TRCCCQD18...\\n29       Re:  RE: Carey Service Reminder for Richard Je...\\n                               ...                        \\n28840    Flight tickets from Delhi to Pune <<#1027898-5...\\n28841    RE: DeepakTripathi_Travel Request_6Jul Jun {{:...\\n28842    RE: FW: Reserva a MEX 30JUN <<#2732132-6507997...\\n28843    CHANGE OF RETURN TKT TO 07.07.18N Mrs Andrea M...\\n28844    RE: Approval of Request 43LYJ for Ravindra Mat...\\n28845    RE: Re: Trip itinerary for Mr Suwalit CHOOPREE...\\n28846    Action Required: Capital One Welcomes Dennis L...\\n28847    Travel Document for: MAURICIO DR SUBIETA - Tra...\\n28848    Travel Document for: AEKANG KAY HONG - Travel ...\\n28849    Travel Document for: JOSEPH ADEREMI ADEYEMI - ...\\n28850    Travel Document for: MARK E GRIMES - Travel Da...\\n28851    Travel Document for: SHARON D LARKIN - Travel ...\\n28852    Travel Document for: MICHAEL ARTHUR RAFFERTY -...\\n28853    Travel Document for: FRANK M TERLIZZI - Travel...\\n28854    Travel Document for: PASCHAL OGE MAFIANA - Tra...\\n28855    Travel Document for: ESIMAJE ONORITSEBAWOR BRI...\\n28856    Travel Document for: LAURA DULA - Travel Date:...\\n28857    Travel Document for: JEFF ALAN BRUNNER - Trave...\\n28858    Travel Document for: PASCHAL OGE MAFIANA - Tra...\\n28859    Travel Document for: LESLIE LENETTE ALLEN - Tr...\\n28860    Travel Document for: FRANCOIS MR MELLET - Trav...\\n28861    Travel Document for: SHARON D LARKIN - Travel ...\\n28862    Itin For MATTHEW LAWRENCE HOWARTH 26JUN  **Do ...\\n28863    Travel Document for: JANET A ENGLUND - Travel ...\\n28864    Travel Document for: MICAH MR WILSON - Travel ...\\n28865    Travel to Mont Joli  Hi,\\\\n\\\\nI will be travelli...\\n28866    Your Case 11955443 Has Been Updated (Subj: Dou...\\n28867    ##6881396# COPA AIRLINES   Dear Mrs. Perez Gre...\\n28868    Travel Reservation to BRUXELLES MIDI on July 0...\\n28869    RE: MAL#1453 - Mohamed El Badawy - Mali <<#309...\\nName: text, Length: 28870, dtype: object'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
